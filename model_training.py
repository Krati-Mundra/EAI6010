# -*- coding: utf-8 -*-
"""model_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bDlU9jMrfizGAtkYtMyetGrFs8fVewTg
"""

"""
This script trains a machine learning model for real estate price prediction using the Ames Housing dataset.
It processes the real dataset and trains a model that will be used by the Flask API.
"""
import os
import pickle
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import logging

# Configure logging
logging.basicConfig(level=logging.INFO,
                   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def load_ames_housing_dataset():
    """
    Load and preprocess the Ames Housing dataset

    Returns:
    - X: Features (including square feet, bedrooms, bathrooms, and other important features)
    - y: Target (sale price)
    """
    logger.info("Loading Ames Housing dataset...")

    # Load the dataset
    data_path = os.path.join('data', 'AmesHousing.csv')
    df = pd.read_csv(data_path)

    # Extract target variable (SalePrice)
    y = df['SalePrice'].values

    # Extract key features
    # For simplicity in this version, we'll use:
    # - Gr Liv Area: Above grade (ground) living area square feet
    # - Bedroom AbvGr: Number of bedrooms above grade
    # - Full Bath: Number of full bathrooms above grade
    # - Total Bsmt SF: Total square feet of basement area
    # - Year Built: Original construction date
    # - Overall Qual: Overall material and finish quality (1-10)

    # Fill any missing values
    df['Total Bsmt SF'] = df['Total Bsmt SF'].fillna(0)

    features = [
        'Gr Liv Area',       # Living area square feet (similar to our previous square_feet)
        'Bedroom AbvGr',     # Bedrooms
        'Full Bath',         # Full bathrooms
        'Total Bsmt SF',     # Basement square feet
        'Year Built',        # Year the house was built
        'Overall Qual'       # Overall quality rating (1-10)
    ]

    X = df[features].values

    logger.info(f"Dataset loaded successfully with {X.shape[0]} samples and {X.shape[1]} features")

    return X, y

def train_and_save_model():
    """Train a model and save it to a file"""
    # Load the real dataset
    logger.info("Loading Ames Housing dataset...")
    X, y = load_ames_housing_dataset()

    # Scale the features for better model performance
    logger.info("Scaling features...")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )

    # Train linear regression model
    logger.info("Training linear regression model...")
    lin_reg = LinearRegression()
    lin_reg.fit(X_train, y_train)

    # Evaluate linear regression model
    y_pred_lin = lin_reg.predict(X_test)
    lin_mse = mean_squared_error(y_test, y_pred_lin)
    lin_r2 = r2_score(y_test, y_pred_lin)

    logger.info(f"Linear Regression: MSE={lin_mse:.2f}, R²={lin_r2:.2f}")

    # Train random forest model
    logger.info("Training random forest model...")
    rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_reg.fit(X_train, y_train)

    # Evaluate random forest model
    y_pred_rf = rf_reg.predict(X_test)
    rf_mse = mean_squared_error(y_test, y_pred_rf)
    rf_r2 = r2_score(y_test, y_pred_rf)

    logger.info(f"Random Forest: MSE={rf_mse:.2f}, R²={rf_r2:.2f}")

    # Choose the better model
    if rf_r2 > lin_r2:
        logger.info("Random Forest performed better. Saving this model.")
        final_model = rf_reg
    else:
        logger.info("Linear Regression performed better. Saving this model.")
        final_model = lin_reg

    # Save model with additional metadata (feature names and scaler)
    logger.info("Saving model to model.pkl")
    model_data = {
        'model': final_model,
        'scaler': scaler,
        'features': [
            'Gr Liv Area',       # Living area square feet
            'Bedroom AbvGr',     # Bedrooms
            'Full Bath',         # Full bathrooms
            'Total Bsmt SF',     # Basement square feet
            'Year Built',        # Year the house was built
            'Overall Qual'       # Overall quality rating (1-10)
        ]
    }

    with open("model.pkl", "wb") as f:
        pickle.dump(model_data, f)

    logger.info("Model training and saving completed!")

    # Return the model data for manual testing
    return model_data

if __name__ == "__main__":
    model_data = train_and_save_model()

    # Access the trained model from the model_data dictionary
    model = model_data['model']
    scaler = model_data['scaler']
    features = model_data['features']

    # Print some sample predictions
    sample_houses = [
        # Living Area, Bedrooms, Full Bath, Basement SF, Year Built, Overall Quality
        [1500, 3, 2, 800, 2000, 7],  # Modern average house
        [2500, 4, 3, 1200, 2010, 8],  # Large newer house
        [1000, 2, 1, 600, 1970, 5],   # Smaller older house
    ]

    print("\nSample Predictions:")
    print("------------------")
    for house in sample_houses:
        # Scale the features
        scaled_house = scaler.transform([house])
        prediction = model.predict(scaled_house)[0]
        print(f"House with {house[0]} sq ft, {house[1]} bedrooms, {house[2]} bathrooms, {house[3]} basement sq ft, built in {house[4]}, quality {house[5]}/10: ${prediction:,.2f}")